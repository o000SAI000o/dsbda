### Step-by-Step Explanation of the Code:

1. **Importing Libraries**:
   - The necessary libraries for data manipulation and visualization are imported:
     - `numpy` for numerical operations.
     - `pandas` for data manipulation and handling datasets.
     - `matplotlib.pyplot` and `seaborn` for visualization.
     - `scipy.stats` for statistical operations.
     - `LabelEncoder` from `sklearn.preprocessing` for encoding categorical labels.

2. **Loading the Dataset**:
   - The dataset `autodata.csv` is loaded using `pandas.read_csv` and stored in a DataFrame `df`. The dataset is printed for initial inspection.

3. **Initial Dataset Inspection**:
   - The first 10 rows of the dataset are printed using `df.head(10)`, and the last 10 rows are displayed with `df.tail(10).to_string()`.
   - A random sample of 10 rows is shown using `df.sample(10)` to get a glimpse of the data.
   - Basic dataset information like its shape, data types, and summary statistics are displayed using `df.info()` and `df.describe()`.

4. **Missing Data Detection**:
   - Missing values are checked using `df.isnull()` and `df.notnull()`.
   - The total number of missing values is calculated using `df.isnull().sum()`.
   - We observe missing data in columns: `stroke`, `horsepower`, `peak-rpm`, and `num-of-doors`.

5. **Handling Missing Data**:
   - The missing values in the `stroke`, `horsepower`, and `peak-rpm` columns are replaced with the mean values of those columns using `astype("float").mean()` and `replace()`.
   - For `num-of-doors`, the missing values are replaced with the most frequent value using the `mode()` function and `replace()`.

6. **Dropping Rows with Missing Data**:
   - Any rows with missing data in the `horsepower-binned` column are dropped using `dropna()`.
   - The index is reset using `reset_index(drop=True)` to maintain a continuous index.

7. **Data Standardization**:
   - The columns `city-mpg` and `highway-mpg` are converted to their respective liters per 100 kilometers using the formula `235 / mpg`, and the results are stored in the new columns `city-L/100km` and `highway-L/100km`.

8. **Data Normalization**:
   - The `length`, `width`, and `height` columns are normalized by dividing them by their respective maximum values using the formula `df[column] = df[column] / df[column].max()`.

9. **Binning (Discretization)**:
   - The `horsepower` column is divided into three bins: `Low`, `Medium`, and `High` using `pd.cut()`.
   - A histogram of the `horsepower` values is plotted before binning, and the resulting bin counts are visualized using a bar plot.

10. **Peak-RPM Distribution Plot**:
    - A histogram is plotted for the `peak-rpm` column to visualize its distribution.

11. **Outlier Detection Using IQR**:
    - A function `detect_outliers()` is defined to detect outliers using the Interquartile Range (IQR) method. This function calculates the lower and upper bounds and returns the rows where values fall outside these bounds.
    - Outliers in the `horsepower` column are detected and printed.

12. **Removing Outliers**:
    - The outliers in the `horsepower` column are removed by filtering the DataFrame to exclude rows with outlier values.

13. **Label Encoding**:
    - The `horsepower-binned` column is encoded using `LabelEncoder` to convert the categorical labels `Low`, `Medium`, and `High` into numeric values 0, 1, and 2, respectively.

---

### Example Output and Explanations:

#### 1. **Initial Dataset**:
```python
First few rows of the dataset:
    make  fuel-type  aspiration  ...   city-mpg  highway-mpg  price
0   alfa-romero      gas     std   ...    21         27          13495
1   alfa-romero      gas     std   ...    21         27          16500
...
```

#### 2. **Missing Values**:
```python
Missing data summary:
stroke : 4 missing data
horsepower: 2 missing data
peak-rpm: 2 missing data
num-of-doors: 2 missing data
```

#### 3. **Handling Missing Data (Replacement)**:
```python
Average of stroke: 3.255
Average of horsepower: 122.0
Average of peak-rpm: 5140.0
```

#### 4. **Binned Data**:
```python
horsepower-binned after binning:
Low     50
Medium  100
High    25
```

#### 5. **Outliers**:
```python
Outliers in horsepower:
   horsepower
0        300
...
```

#### 6. **Data After Removing Outliers**:
```python
Data after removing outliers:
    horsepower
count    100
mean      120
std       30
...
```

---

### Conclusion:
This code performs various essential data preprocessing steps:
- Handling missing data by imputation and replacement.
- Standardizing and normalizing data.
- Binning continuous variables for easier analysis.
- Detecting and removing outliers.
- Label encoding categorical columns for machine learning algorithms.

These techniques are foundational for preparing data for further analysis or machine learning.